# å¿«é€Ÿå¼€å§‹æŒ‡å—

## âš¡ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <é¡¹ç›®åœ°å€>
cd Reshaped_Transformer-main

# å®‰è£…ä¾èµ–ï¼ˆé€‰æ‹©å…¶ä¸€ï¼‰
# æ–¹æ¡ˆ1: CPUç‰ˆæœ¬ï¼ˆæ¨èå…¥é—¨ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# æ–¹æ¡ˆ2: GPUç‰ˆæœ¬ï¼ˆæ¨èè®­ç»ƒï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install joblib scikit-learn fastdtw tensorboard numpy scipy pandas
```

### 2. æ•°æ®æ£€æŸ¥

```bash
# æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
ls *dualtask.joblib

# åº”è¯¥çœ‹åˆ°ä»¥ä¸‹æ–‡ä»¶ï¼š
# trainX_dualtask.joblib     trainYclass_dualtask.joblib     trainYtrend_dualtask.joblib
# valX_dualtask.joblib       valYclass_dualtask.joblib       valYtrend_dualtask.joblib  
# testX_dualtask.joblib      testYclass_dualtask.joblib      testYtrend_dualtask.joblib
```

### 3. å¼€å§‹è®­ç»ƒ

```bash
# æ–¹å¼1: ä¸€é”®è®­ç»ƒï¼ˆæ¨èï¼‰
python train_model.py

# æ–¹å¼2: å®Œæ•´è®­ç»ƒè„šæœ¬
python main.py --mode train --epochs 50 --batch_size 16
```

### 4. ç›‘æ§è®­ç»ƒ

åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£ï¼š

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir=logs/

# æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:6006
```

## ğŸ¯ é¢„æœŸç»“æœ

### è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```
============================================================
è½´æ‰¿æ•…éšœè¯Šæ–­ - é‡å¡‘çš„Transformeræ¨¡å‹è®­ç»ƒ
============================================================
2024-xx-xx 10:00:00,000 INFO æ¨¡å‹é…ç½®:
2024-xx-xx 10:00:00,000 INFO   batch_size: 16
2024-xx-xx 10:00:00,000 INFO   learning_rate: 0.001
2024-xx-xx 10:00:00,000 INFO   epochs: 50
...
2024-xx-xx 10:00:00,000 INFO è®­ç»ƒé›†æ ·æœ¬æ•°: 1386
2024-xx-xx 10:00:00,000 INFO éªŒè¯é›†æ ·æœ¬æ•°: 462
2024-xx-xx 10:00:00,000 INFO æµ‹è¯•é›†æ ·æœ¬æ•°: 462
2024-xx-xx 10:00:00,000 INFO æ¨¡å‹æ€»å‚æ•°é‡: 1,189,263

Epoch 1/50: Train Loss=2.5000 Val Loss=2.2000 Acc=30.00%
Epoch 2/50: Train Loss=2.0000 Val Loss=1.8000 Acc=45.00%
...
Epoch 25/50: Train Loss=0.5000 Val Loss=0.4500 Acc=92.50%
```

### æ€§èƒ½æŒ‡æ ‡

è®­ç»ƒå®Œæˆåï¼Œæ‚¨åº”è¯¥çœ‹åˆ°ç±»ä¼¼çš„ç»“æœï¼š

```
========================================
æµ‹è¯•é›†è¯„ä¼°ç»“æœ:
æ€»æŸå¤±: 0.4500
åˆ†ç±»æŸå¤±: 0.2000
å›å½’æŸå¤±: 0.2500
å‡†ç¡®ç‡: 92.50%
ç²¾ç¡®ç‡: 0.9200
å¬å›ç‡: 0.9250
F1åˆ†æ•°: 0.9225
MSE: 0.0850
MAE: 0.2100
DTWè·ç¦»: 15.50
========================================
```

## ğŸ”§ å¸¸è§é—®é¢˜è§£å†³

### Q1: ModuleNotFoundError: No module named 'torch'

```bash
# è§£å†³æ–¹æ¡ˆï¼šé‡æ–°å®‰è£…PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### Q2: CUDA out of memory

```bash
# è§£å†³æ–¹æ¡ˆ1ï¼šå‡å°æ‰¹å¤§å°
python train_model.py  # å·²è®¾ç½®batch_size=16

# è§£å†³æ–¹æ¡ˆ2ï¼šä½¿ç”¨CPUè®­ç»ƒ
python main.py --mode train --batch_size 8
```

### Q3: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

```bash
# è§£å†³æ–¹æ¡ˆ1ï¼šå‡å°‘epochæ•°å¿«é€ŸéªŒè¯
python main.py --mode train --epochs 10

# è§£å†³æ–¹æ¡ˆ2ï¼šä½¿ç”¨GPUï¼ˆå¦‚æœæœ‰ï¼‰
python main.py --mode train  # ä¼šè‡ªåŠ¨æ£€æµ‹GPU
```

### Q4: æ— æ³•æ‰¾åˆ°æ•°æ®æ–‡ä»¶

```bash
# æ£€æŸ¥å½“å‰ç›®å½•
pwd

# ç¡®ä¿åœ¨æ­£ç¡®çš„é¡¹ç›®ç›®å½•
cd Reshaped_Transformer-main

# éªŒè¯æ•°æ®æ–‡ä»¶
python -c "import joblib; print('æ•°æ®åŠ è½½æ­£å¸¸' if len(joblib.load('trainX_dualtask.joblib')) > 0 else 'æ•°æ®æ–‡ä»¶æœ‰é—®é¢˜')"
```

## ğŸ“Š ç»“æœåˆ†æ

### 1. TensorBoardå¯è§†åŒ–

è®­ç»ƒå¼€å§‹åï¼Œåœ¨æµè§ˆå™¨æ‰“å¼€ `http://localhost:6006` æŸ¥çœ‹ï¼š

- **Lossæ›²çº¿**: è§‚å¯Ÿè®­ç»ƒå’ŒéªŒè¯æŸå¤±å˜åŒ–
- **å‡†ç¡®ç‡æ›²çº¿**: ç›‘æ§åˆ†ç±»ä»»åŠ¡æ€§èƒ½
- **ä»»åŠ¡æƒé‡**: æŸ¥çœ‹ä¸ç¡®å®šæ€§åŠ æƒçš„åŠ¨æ€å˜åŒ–

### 2. æ—¥å¿—åˆ†æ

è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `logs/training.log`ï¼š

```bash
# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
tail -f logs/training.log

# æœç´¢æœ€ä½³ç»“æœ
grep "æœ€ä½³" logs/training.log
```

### 3. æ¨¡å‹æ–‡ä»¶

è®­ç»ƒå®Œæˆåæ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶ï¼š

```bash
ls logs/
# best_model.pth          - æœ€ä½³æ¨¡å‹æƒé‡
# events.out.tfevents.*   - TensorBoardæ—¥å¿—
# training.log            - è®­ç»ƒæ—¥å¿—
```

## ğŸš€ ä¸‹ä¸€æ­¥

### 1. æ¨¡å‹è¯„ä¼°

```bash
# ä»…è¿è¡Œè¯„ä¼°ï¼ˆåŠ è½½å·²è®­ç»ƒæ¨¡å‹ï¼‰
python main.py --mode eval
```

### 2. è‡ªå®šä¹‰å‚æ•°

```bash
# è°ƒæ•´æ¨¡å‹ç»“æ„
python main.py --embed_dim 256 --num_heads 16 --num_layers 4

# è°ƒæ•´è®­ç»ƒç­–ç•¥
python main.py --learning_rate 0.0005 --batch_size 32 --epochs 100
```

### 3. å®æ—¶é¢„æµ‹

```python
# åˆ›å»ºé¢„æµ‹è„šæœ¬ predict.py
from models.model import MultiTaskModel
import torch
import joblib

# åŠ è½½æ¨¡å‹
model = MultiTaskModel(...)
model.load_state_dict(torch.load('logs/best_model.pth'))
model.eval()

# åŠ è½½æµ‹è¯•æ•°æ®
test_data = joblib.load('testX_dualtask.joblib')

# è¿›è¡Œé¢„æµ‹
with torch.no_grad():
    sample = torch.FloatTensor(test_data[0:1]).unsqueeze(-1)
    class_logits, reg_out = model(sample)
    
    predicted_class = torch.argmax(class_logits, dim=1).item()
    confidence = torch.softmax(class_logits, dim=1).max().item()
    
    print(f"é¢„æµ‹æ•…éšœç±»å‹: {predicted_class}")
    print(f"ç½®ä¿¡åº¦: {confidence:.4f}")
```

## ğŸ“ æç¤ºå’ŒæŠ€å·§

### æ€§èƒ½ä¼˜åŒ–

1. **ä½¿ç”¨æ›´å¤§çš„æ‰¹å¤§å°**: å¦‚æœå†…å­˜å…è®¸ï¼Œå¢åŠ batch_sizeåˆ°32æˆ–64
2. **å¯ç”¨æ··åˆç²¾åº¦**: åœ¨æ”¯æŒçš„GPUä¸Šä½¿ç”¨AMPåŠ é€Ÿè®­ç»ƒ
3. **æ•°æ®å¹¶è¡Œ**: å¤šGPUè®­ç»ƒæ—¶ä½¿ç”¨DataParallel

### æ¨¡å‹è°ƒä¼˜

1. **å­¦ä¹ ç‡è°ƒåº¦**: å°è¯•CosineAnnealingæˆ–StepLR
2. **æ­£åˆ™åŒ–**: è°ƒæ•´dropoutå’Œweight_decay
3. **æ¨¡å‹ç»“æ„**: æ ¹æ®æ•°æ®ç‰¹ç‚¹è°ƒæ•´window_sizeå’Œembed_dim

### å®éªŒç®¡ç†

1. **ç‰ˆæœ¬æ§åˆ¶**: ä½¿ç”¨gitç®¡ç†ä»£ç ç‰ˆæœ¬
2. **å®éªŒè®°å½•**: è®°å½•æ¯æ¬¡å®éªŒçš„å‚æ•°å’Œç»“æœ
3. **æ¨¡å‹å¯¹æ¯”**: ä¿å­˜å¤šä¸ªæ¨¡å‹ç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”

å¼€å§‹æ‚¨çš„è½´æ‰¿æ•…éšœè¯Šæ–­ä¹‹æ—…å§ï¼ğŸ‰ 